{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple tutorial of TensorFlow and Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction - What is TensorFlow\n",
    "\n",
    "TensorFlow is a framework developed by Google which is designed mainly for machine learning tasks, especially neural networks. It highly abstracts the usage of models so that users only need to adjust several very necessary parameters and TensorFlow will care about all the mechanism and realization details underneath for you. It also opens low level structures as well as shaped model parts for users to use and flexibly assemble their own customized models. TensorFlow supports GPU mode as well and has libraries for many programming languages including Python, C++, Java and Go.\n",
    "\n",
    "In this tutorial, I will introduce all the way from basic and core components like Tensors and Operations to high level all kinds of encapsulated models, i.e. Estimators, together with examples. Also, a real-world dataset is used in the examples. Machine learning model usage sample codes are covered within the steps of a simple and complete basic data science analysis steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Installation and Verification\n",
    "\n",
    "In this section, I will introduce how to install TensorFlow's Python library on your computer and how to test if your installation works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Installation\n",
    "\n",
    "This link gives a very detailed installation guide for different operating systems (Ubuntu, MacOS, Window): https://www.tensorflow.org/install/. Here is the simplest one using pip from command line without GPU support:\n",
    "\n",
    "$ pip install tensorflow\n",
    "\n",
    "It is recommended to use the non-GPU version of TensorFlow first for exploring the basics easier. If you want to install the GPU one, please refer to the above link as well for detailed installation steps and notices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Validate your installation\n",
    "\n",
    "Use the short program below to validate if tensorflow is ready to run on your machine. It should print out \"Hello, TensorFlow\" on your console.\n",
    "\n",
    "(Credit: https://www.tensorflow.org/install/install_linux#ValidateYourInstallation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuqih/ENTER/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TensorFlow Big Picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/TensorFlowProgrammingEnvironment.png)\n",
    "\n",
    "Credit: https://www.tensorflow.org/get_started/get_started_for_beginners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This picture shows the hierarchical structure of TensorFlow framework. Basically, it provides the high level OOP APIs called Estimators which are complete machine learning models. You can use them in really simple ways to run a fairly complicated machine learning task, especially neural network tasks. What's more, you can also use the middle level APIs which are major and common model components, for example Layers to build layers of network and Datasets to pre-process raw data into usable forms and feed data to the model, to customize your own implementations. The Python realization we are using in this tutorial is built upon lower level C++ cores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main Components of TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Intuition\n",
    "\n",
    "Using TensorFlow to do computation follows a slight different structure from traditional procedures programming using C, Java or Python. Instead of doing calculation along the execution of lines of programs, TensorFlow is mainly composed of two parts: \n",
    "\n",
    "1. building computaion steps, i.e. the graph\n",
    "2. take in input values into the graph and generate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if I have the python code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 24 38\n"
     ]
    }
   ],
   "source": [
    "def formula1(a, b):\n",
    "    return a * b * 2\n",
    "\n",
    "def formula2(a, b):\n",
    "    return a + b + 10\n",
    "\n",
    "a = 1\n",
    "b = 2\n",
    "c = 3\n",
    "d = 4\n",
    "\n",
    "x = formula1(a, b)\n",
    "y = formula1(c, d)\n",
    "z = formula2(x, y)\n",
    "\n",
    "print(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then when running, this program will perform the operations line by line. Specifically, when running at line 7, the variable \"a\" is assigned value 1, when running at line 12, the calculation of \"formula1(a,b)\" is computed and the variable \"x\" is assigned value 4. However in TensorFlow, all the calculation as well as value assignments will not be executed unless explicitly asked to. Otherwise only the calculation process will be formed, but values won't be passed in and calculation will not happen. Thus, I think a likely analog could be merging all the formulas into a big one and wait to be explicitly asked to do the computation. And the above program can be rewritten as follows to mimic TensorFlow structure: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "def formula1(a, b):\n",
    "    return a * b * 2\n",
    "\n",
    "def formula2(a, b):\n",
    "    return a + b + 10\n",
    "\n",
    "# this is to mimic the explicit call to execute the calculation\n",
    "def calculate(z):\n",
    "    print(z)\n",
    "\n",
    "# merge seperate formulas together to be one big complete formula\n",
    "z = formula2(formula1(a, b), formula1(c, d))\n",
    "# ==>\n",
    "z = formula1(a,b) + formula1(c,d) + 10\n",
    "# ==>\n",
    "z = a * b * 2 + c * d * 2 + 10\n",
    "\n",
    "a = 1\n",
    "b = 2\n",
    "c = 3\n",
    "d = 4\n",
    "\n",
    "# all the value assignments and calculations wait here to be executed\n",
    "\n",
    "# ======================================================================\n",
    "\n",
    "# explicitly issue to execution command, all the needed value assignments \n",
    "# and calculations in order to calculate \"z\" are traced back to and done.\n",
    "# specifically, \"z\" traces back to how it is formed, and that calls the \n",
    "# \"formula2\" function. And since in this calculation \"formula2\" needs two \n",
    "# parameters which are \"formula1(a,b)\" and \"formula1(c,d)\", these two \n",
    "# calculations are traced to and executed before \"formula2\" got executed \n",
    "# to generate value of \"z\". And in order to calculate \"formula1(a,b)\" and \n",
    "# \"formula1(c,d)\", variable \"a\", \"b\", \"c\" and \"d\" are traced to and assigned \n",
    "# the values 1, 2, 3 and 4 before calculations are down.\n",
    "calculate(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name TensorFlow is a great concise and accurate description of its internal core structure of this framework. That is Tensors (any dimension of arrays) flowing within Graphs (a composition of nodes and edges where nodes represent computation operations and edges represent data flow) in order to realize certain computations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors, as roughly mentioned above, are the n-dimensional arrays flowing in the edges of a Graph. And it is worthwhile to mention that most TensorFlow functions return tf.Tensors.\n",
    "\n",
    "Here is an example of how to create simple constant Tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.constant(1.0, dtype=tf.float32)\n",
    "b = tf.constant(2.0) # dtype=tf.float32 implicitly\n",
    "c = tf.constant(3, dtype=tf.int32)\n",
    "d = tf.constant(4) # dtype=tf.int32 implicitly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, Tensors are not given values yet until being explicitly asked to. Thus, the are all empty values at this moment, which can be shown as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_3:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Const_4:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that all the Tensors have value 0 instead of seemingly given values 1.0, 2.0, 3 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, Tensors can have any dimensions or ranks. See the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_5:0\", shape=(4,), dtype=int32)\n",
      "Tensor(\"Const_6:0\", shape=(2, 2), dtype=int32)\n",
      "Tensor(\"Const_7:0\", shape=(4, 1), dtype=int32)\n",
      "Tensor(\"Const_8:0\", shape=(2, 2, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "e = tf.constant([1, 2, 3, 4]) # rank 1\n",
    "f = tf.constant([[1, 2], [3, 4]]) # rank 2\n",
    "g = tf.constant([[1], [2], [3], [4]]) # rank 2\n",
    "h = tf.constant([[[1], [2]], [[3], [4]]]) # rank 3\n",
    "print(e)\n",
    "print(f)\n",
    "print(g)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the \"shape\" parameter shown here, Tensors can be built very flexibly. Actually TensorFlow uses numpy arrays to represent Tensor values in Python. This enhances its convenience to use in large scale mathematical computations or machine learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously constant is far from enough to represent all the Tensors. So besides constants, TnesorFlow also provides other types of Tensors. Specifically they are:\n",
    "- tf.Variable\n",
    "- tf.constant\n",
    "- tf.placeholder\n",
    "- tf.SparseTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, placeholders are used to wait for external input which will be fed in later. Usage examples are shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us one placeholder waiting for a floating point number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Variable is the only one among them whose value can be changed during the program running. In other word, all the other three types are immutable once assigned. To create a tf.Variable, it is recommended to use tf.get_variable method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var = tf.get_variable(\"var\", [1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the name and shape of the Variable is specified. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations take Tensors as inputs, doing calculations with them and output results as Tensors. They make up the nodes of a graph. Common operations are like addition and multiplication, which are the most basic and widely used operations for machine learning tasks, especially in neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(), dtype=float32)\n",
      "Tensor(\"mul:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "add = a + b\n",
    "mul = c * d\n",
    "print(add)\n",
    "print(mul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since not explicitly asked to run yet, the operations are just built and ready to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are finally here to explicit run the value assignments and computations. A Session object encapsulates the environment in which Operation objects are executed, and Tensor objects are evaluated. First of all, let's build a simple tf.Session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to use this session, an encapsulation in which Tensors flow through the Operations, to run the Operations built above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(add))\n",
    "print(sess.run(mul))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worthwhile to mention that in order to calculate value for \"add\", only the \"add\" itself needs to be passed into tf.Session().run() and all the value assignments and calculations which are prerequisite for this \"add\" will be automatically figured out and get calculated beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Realize Machine Learning using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we already have a basic understanding about how TensorFlow works essencially. In this section let's try to use the basic components we have presented to build a realization of a simple machine learning algorithm - linear regression - as well as TensorFlow's straight-forward high level methods directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Low Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's realize it using low level model components. See if the model can guess the mathmatical relation between my features and labels, i.e. y=x+1\n",
    "\n",
    "Credit: https://www.tensorflow.org/programmers_guide/low_level_intro#training_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict before training:\n",
      "[[ 0.       ]\n",
      " [-0.6250793]\n",
      " [-1.2501585]\n",
      " [-1.8752378]\n",
      " [-2.500317 ]\n",
      " [-3.1253963]]\n",
      "predict after training:\n",
      "[[0.9999988]\n",
      " [1.9999992]\n",
      " [2.9999995]\n",
      " [3.9999998]\n",
      " [5.       ]\n",
      " [6.000001 ]]\n"
     ]
    }
   ],
   "source": [
    "# First of all, let's build some constants as the data features \n",
    "# and labels used for training the model later.\n",
    "x = tf.constant([[0], [1], [2], [3], [4], [5]], dtype=tf.float32)\n",
    "y = tf.constant([[1], [2], [3], [4], [5], [6]], dtype=tf.float32)\n",
    "\n",
    "# Then we employ the Layers, which is the interface of TensorFlow\n",
    "# to build computing relations or nodes and edges. The tf.layers.Dense() \n",
    "# we use here is a densely connected layer class which takes in \n",
    "# input vectors and output a single value.\n",
    "regressor = tf.layers.Dense(units=1)\n",
    "\n",
    "# pass in features\n",
    "predictions = regressor(x)\n",
    "\n",
    "# choose loss function as MSE \n",
    "loss_function = tf.losses.mean_squared_error(labels=y, predictions=predictions)\n",
    "\n",
    "# choose optimization method as gradient descent\n",
    "# with learning rate 0.05\n",
    "optimization = tf.train.GradientDescentOptimizer(0.05)\n",
    "\n",
    "# build training process\n",
    "training = optimization.minimize(loss_function)\n",
    "\n",
    "# before running, simply run the internal initializer to initialize\n",
    "# all the variables which cannot run otherwise\n",
    "initialization = tf.global_variables_initializer()\n",
    "\n",
    "# run TensorFlow Graph\n",
    "sess = tf.Session()\n",
    "sess.run(initialization)\n",
    "\n",
    "# show prediction before training\n",
    "# which is very much like random number\n",
    "print(\"predict before training:\")\n",
    "print(sess.run(predictions))\n",
    "\n",
    "# training with 1000 steps\n",
    "for i in range(1000):\n",
    "    sess.run((training, loss_function))\n",
    "\n",
    "# show the final prediction after training\n",
    "# which is very much the same as expected\n",
    "print(\"predict after training:\")\n",
    "print(sess.run(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 High Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's realize the linear regression model using [tf.estimator.LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor) with exactly the same linear relation as the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp3y7l13x5\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp3y7l13x5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f57641f6ba8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp3y7l13x5/model.ckpt.\n",
      "INFO:tensorflow:loss = 84.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1185.54\n",
      "INFO:tensorflow:loss = 0.0003477838, step = 101 (0.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 1326.98\n",
      "INFO:tensorflow:loss = 4.724595e-05, step = 201 (0.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 1300.45\n",
      "INFO:tensorflow:loss = 0.00010210703, step = 301 (0.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1300.01\n",
      "INFO:tensorflow:loss = 7.1263756e-05, step = 401 (0.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1457.19\n",
      "INFO:tensorflow:loss = 4.828461e-05, step = 501 (0.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 1311.97\n",
      "INFO:tensorflow:loss = 1.5231603e-05, step = 601 (0.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 1304.65\n",
      "INFO:tensorflow:loss = 5.582712e-06, step = 701 (0.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 1307.6\n",
      "INFO:tensorflow:loss = 5.6491417e-06, step = 801 (0.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 1414.42\n",
      "INFO:tensorflow:loss = 1.6965978e-06, step = 901 (0.070 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp3y7l13x5/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.4815987e-06.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-31-22:45:17\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp3y7l13x5/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-31-22:45:17\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 3.5146672e-06, global_step = 1000, loss = 7.0293345e-06\n",
      "loss: 7.0293345e-06\n",
      "=========================================\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp3y7l13x5/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "Prediction is \"16.997535705566406\", expected \"17\"\n",
      "\n",
      "Prediction is \"17.997303009033203\", expected \"18\"\n",
      "\n",
      "Prediction is \"18.997068405151367\", expected \"19\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# specify data for train, evaluate and predict new\n",
    "train_x = {'x': np.array([1, 2, 3, 4, 5, 6, 7, 8])}\n",
    "train_y = np.array([2, 3, 4, 5, 6, 7, 8, 9])\n",
    "test_x = {'x': np.array([-1, -2, -3, -4])}\n",
    "test_y = np.array([0, -1, -2, -3])\n",
    "predict_x = {'x': np.array([16, 17, 18])}\n",
    "predict_y = np.array([17, 18, 19])\n",
    "\n",
    "# Create input functions\n",
    "def input_fn_train(features, labels, batch_size): \n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    return dataset.shuffle(10).repeat().batch(batch_size)\n",
    "\n",
    "def input_fn_evaluate(features, labels, batch_size): \n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "    # Batch the examples.\n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "def input_fn_predict(features, batch_size):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(features)\n",
    "    # Batch the examples.\n",
    "    return dataset.batch(batch_size)\n",
    "   \n",
    "\n",
    "# Build BaselineRegressor\n",
    "feature_columns = [tf.feature_column.numeric_column(key='x')]\n",
    "regressor = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "\n",
    "# Fit model.\n",
    "regressor.train(input_fn=lambda:input_fn_train(train_x, train_y, 3), steps=1000)\n",
    "\n",
    "# Evaluate squared-loss between the test and train targets.\n",
    "loss = regressor.evaluate(input_fn=lambda:input_fn_evaluate(test_x, test_y, 3))[\"loss\"]\n",
    "print(\"loss:\", loss)\n",
    "\n",
    "# predict outputs the mean value seen during training.\n",
    "predictions = regressor.predict(input_fn=lambda:input_fn_predict(predict_x, 3))\n",
    "print(\"=========================================\")\n",
    "template = ('\\nPrediction is \"{}\", expected \"{}\"')\n",
    "for pred, pred_y in zip(predictions, predict_y):\n",
    "    print(template.format(pred[\"predictions\"][0], pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the above two realizations, we can easily find that the high level Estimator is more structured. The steps are almost the same for different Estimators, hiding the complicated and variant details underneath. So the usage are more universal. \n",
    "\n",
    "Generally speaking, using an Estimator follows these four steps:\n",
    "1. Write one or more dataset importing functions.\n",
    "2. Define the feature columns.\n",
    "3. Instantiate the relevant pre-made Estimator.\n",
    "4. Call a training, evaluation, or inference method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analysis of Real Dataset\n",
    "\n",
    "Having known how to build machine learning models with TensorFlow, now let's go a little further to analyze a real world dataset, called [\"Pima Indians Diabetes Database\"](https://www.kaggle.com/uciml/pima-indians-diabetes-database/data) from Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Dataset overview\n",
    "\n",
    "This dataset gives eight attributes of features together with the outcome whether this person has diabetes or not. All columns are numerical and there is no empty row anywhere. Now let's load this data in and have a look of it generally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "diabetes = pd.read_csv(\"datasets/diabetes.csv\")\n",
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Generate features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split this dataset into training set and test set for later use. In order to spliting dataset propotionally to labels, i.e. to have generally identical percent of positive and negative labels in both sets, I will use the \"train_test_split\" function from scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train,test=train_test_split(diabetes,test_size=0.25,random_state=0,stratify=diabetes['Outcome'])\n",
    "train_x, train_y = train, train.pop(\"Outcome\")\n",
    "test_x, test_y = test, test.pop(\"Outcome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can start to apply different machine learning models on the data, we should first normalize the dataset, which would be greatly benefitial for increasing the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shuqih/ENTER/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
      "432    -0.844335 -1.279049       0.252871      -0.597814 -0.171805 -0.252732   \n",
      "453    -0.547562 -0.059255      -3.570271      -1.287373 -0.692439 -1.571832   \n",
      "706     1.826623 -0.184362      -3.570271      -1.287373 -0.692439 -4.057829   \n",
      "606    -0.844335  1.879904       0.459528       1.345490  1.849992  1.015634   \n",
      "118     0.045984 -0.747344      -0.470426       0.154433 -0.692439 -0.481038   \n",
      "421    -0.547562 -0.841174      -0.057113      -0.159003 -0.032969 -0.760078   \n",
      "3      -0.844335 -0.997558      -0.160441       0.154433  0.123221 -0.493721   \n",
      "157    -0.844335 -0.372022      -0.677082       0.029058  0.478988 -0.861547   \n",
      "400     0.045984 -0.809897      -0.263769      -1.287373 -0.692439  0.000941   \n",
      "497    -0.547562 -1.247772       0.149543      -0.347065 -0.032969 -0.240048   \n",
      "296    -0.547562  0.785218       0.046215       1.094741  2.431367 -0.506405   \n",
      "30      0.342757 -0.372022       0.304536       0.342494 -0.692439  0.508288   \n",
      "201    -0.844335  0.535004       0.666184      -1.287373 -0.692439  1.028318   \n",
      "314     0.936304 -0.372022       0.562856       0.655930 -0.692439  0.495604   \n",
      "32     -0.250789 -1.028834      -0.573754      -0.597814 -0.223868 -0.912282   \n",
      "475    -1.141108  0.503727       0.769512       0.405181 -0.692439 -0.595191   \n",
      "501    -0.250789 -1.153942       0.149543       0.718617 -0.692439  0.660492   \n",
      "293    -0.844335  0.222236      -1.090395       1.533551  0.990945  1.079052   \n",
      "681    -1.141108  1.285646       0.356200       0.969366 -0.692439  2.233265   \n",
      "381    -1.141108 -0.497129      -0.057113       0.091745 -0.692439 -1.521098   \n",
      "346    -0.844335  0.566280      -1.193723      -0.096316  0.027772 -0.417619   \n",
      "34      1.826623  0.034575       0.459528       0.655930 -0.692439 -0.557140   \n",
      "119     0.045984 -0.684790       0.356200      -0.347065 -0.249900 -1.115221   \n",
      "642     0.639530  0.816495       0.562856      -1.287373 -0.692439 -0.316150   \n",
      "248     1.529850  0.097129       0.046215       0.781305  2.795812  0.432186   \n",
      "397    -1.141108  0.316066      -0.160441       1.220115 -0.692439  0.292666   \n",
      "101    -0.844335  0.941602      -0.470426      -1.287373 -0.692439 -0.747395   \n",
      "645    -0.547562  1.129262       0.252871       0.906679  3.125547  0.939532   \n",
      "498     0.936304  2.317779       0.046215       0.781305  0.565761 -0.874231   \n",
      "659    -0.250789 -1.279049       0.666184       0.655930 -0.085032  0.279982   \n",
      "..           ...       ...            ...            ...       ...       ...   \n",
      "487    -1.141108  1.629690       0.459528       0.718617  1.607030  1.840072   \n",
      "749     0.639530  1.285646      -0.367098      -1.287373 -0.692439 -0.975700   \n",
      "622     0.639530  1.942458       1.286153      -1.287373 -0.692439  1.117103   \n",
      "458     1.826623  0.847771       0.769512       1.721613  1.364067  0.711226   \n",
      "45     -1.141108  1.848628      -0.160441       1.157428 -0.692439  1.269307   \n",
      "228     0.045984  2.380333       0.046215       1.157428  5.763428  0.597073   \n",
      "682    -1.141108 -0.809897      -0.263769       1.157428  0.218671  1.599082   \n",
      "359    -0.844335  2.349056       0.356200       0.969366  1.468194  0.571706   \n",
      "171     0.639530  0.409897       0.046215       0.154433  0.435602  0.432186   \n",
      "99     -0.844335  0.034575       1.079497       1.909674  1.216554  2.245949   \n",
      "593    -0.547562 -1.216495      -0.883738       0.091745  0.305443 -0.442987   \n",
      "49      0.936304 -0.497129      -3.570271      -1.287373 -0.692439 -4.057829   \n",
      "104    -0.547562 -1.122665      -0.212105      -1.287373 -0.692439  0.964899   \n",
      "370    -0.250789  1.629690       0.666184       1.721613  3.342478  0.812696   \n",
      "138    -1.141108  0.253513       0.562856      -1.287373 -0.692439 -0.100528   \n",
      "570    -0.250789 -1.341602       0.046215      -1.287373 -0.692439  0.064360   \n",
      "687    -0.844335 -0.434576      -0.987066      -0.096316 -0.692439 -0.468354   \n",
      "303     0.342757 -0.184362       1.492809      -1.287373 -0.692439  2.651826   \n",
      "51     -0.844335 -0.622237      -0.987066      -0.347065 -0.380059 -0.988384   \n",
      "221    -0.547562  1.160539       1.079497      -1.287373 -0.692439 -0.049793   \n",
      "583     1.233077 -0.653513       0.356200      -1.287373 -0.692439  0.850747   \n",
      "231     0.639530  0.409897       0.562856       1.032053  2.518140  1.802021   \n",
      "215     2.420169  0.941602       0.046215       1.220115  1.659093  1.243940   \n",
      "757    -1.141108  0.065852       0.149543      -1.287373 -0.692439  0.546339   \n",
      "657    -0.844335 -0.027978       0.562856       1.721613  1.043009  0.876114   \n",
      "628     0.342757  0.222236       0.562856      -1.287373 -0.692439  0.330716   \n",
      "456    -0.844335  0.441173      -0.780410      -1.287373 -0.692439 -0.671293   \n",
      "398    -0.250789 -1.216495       0.046215      -1.287373 -0.692439 -1.381577   \n",
      "378     0.045984  1.097985       0.304536      -1.287373 -0.692439  2.068378   \n",
      "294    -1.141108  1.254369      -0.987066      -1.287373 -0.692439 -1.280108   \n",
      "\n",
      "     DiabetesPedigreeFunction       Age  \n",
      "432                  0.166372 -0.955839  \n",
      "453                  1.086908  3.295778  \n",
      "706                 -0.636457 -0.275580  \n",
      "606                  2.372641 -0.955839  \n",
      "118                 -0.087153 -0.955839  \n",
      "421                  0.268989 -1.040871  \n",
      "3                   -0.920163 -1.040871  \n",
      "157                  1.089926 -0.870806  \n",
      "400                 -0.938272 -0.190548  \n",
      "497                  0.226735 -0.700742  \n",
      "296                 -0.407077 -0.360612  \n",
      "30                   0.223717  2.275390  \n",
      "201                 -0.711910 -0.445645  \n",
      "314                  1.977263  0.829840  \n",
      "32                  -0.618348 -0.955839  \n",
      "475                 -0.727001  2.190358  \n",
      "501                 -0.618348 -0.445645  \n",
      "293                  0.425933 -0.785774  \n",
      "681                 -0.325587 -0.615709  \n",
      "381                 -0.711910 -0.955839  \n",
      "346                  0.549677 -0.955839  \n",
      "34                   0.121099  0.999905  \n",
      "119                 -0.751146 -1.040871  \n",
      "642                 -0.886963  1.425067  \n",
      "248                 -0.573076  0.064549  \n",
      "397                 -0.832637 -0.955839  \n",
      "101                 -0.883945 -0.955839  \n",
      "645                 -1.019762 -0.275580  \n",
      "498                 -0.932236  1.850228  \n",
      "659                  2.475258 -0.530677  \n",
      "..                        ...       ...  \n",
      "487                  2.073844  2.105325  \n",
      "749                 -0.886963  1.425067  \n",
      "622                  2.985325  0.999905  \n",
      "458                  1.596976  1.510099  \n",
      "45                   4.289167 -0.700742  \n",
      "228                  5.605081 -0.190548  \n",
      "682                 -0.319551 -0.955839  \n",
      "359                  1.216689 -0.360612  \n",
      "171                  0.211644 -0.360612  \n",
      "99                  -0.443295 -0.190548  \n",
      "593                  3.703646 -0.700742  \n",
      "49                  -0.503658 -0.785774  \n",
      "104                  1.382687 -0.530677  \n",
      "370                  5.025596 -0.700742  \n",
      "138                  0.697566 -0.360612  \n",
      "570                 -0.609293  0.489711  \n",
      "687                 -0.877909 -0.360612  \n",
      "303                 -0.793401 -0.445645  \n",
      "51                   0.163354 -0.615709  \n",
      "221                  1.005418  2.785584  \n",
      "583                 -0.850745  0.744808  \n",
      "231                 -0.705874  1.084937  \n",
      "215                  0.815274  0.404679  \n",
      "757                 -0.645511  1.595131  \n",
      "657                  2.082898  0.659776  \n",
      "628                 -0.989580  0.999905  \n",
      "456                  0.649276  2.445455  \n",
      "398                 -0.250133 -0.700742  \n",
      "378                 -0.705874 -0.105515  \n",
      "294                 -0.657584  2.700552  \n",
      "\n",
      "[576 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "features = train_x.columns.values\n",
    "for feature in features:\n",
    "    mean, std = diabetes[feature].mean(), diabetes[feature].std()\n",
    "    train_x.loc[:, feature] = (train_x[feature] - mean) / std\n",
    "    test_x.loc[:, feature] = (test_x[feature] - mean) / std\n",
    "    \n",
    "print(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Analyze with Logistic Regression\n",
    "\n",
    "First of all, since this is a binary classification problem and the number of features is not very big, we can try to start with simple linear model which could be a great choice for such a problem. Let's build a linear classifier - [tf.estimator.LinearClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier) - step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.1 Create input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn_train(features, labels, batch_size): \n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    return dataset.shuffle(10).repeat().batch(batch_size)\n",
    "\n",
    "def input_fn_evaluate(features, labels, batch_size): \n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    # Batch the examples.\n",
    "    return dataset.batch(batch_size)\n",
    "\n",
    "def input_fn_predict(features, batch_size):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(dict(features))\n",
    "    # Batch the examples.\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2 Define the feature columns\n",
    "\n",
    "There is actually much more to say about feature columns. Because sttributes of datasets can have many more types than just numerical data in this example. For example categorical data and strings. In order to coping with those data types, more complicated steps are needed to build feature columns which are suitable of inputing into the machine learning model. That is because machine learning models can only compute upon numerical values. Please check the following link if you wonder how to change other data types into usable numerical representations (https://www.tensorflow.org/get_started/feature_columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_NumericColumn(key='Pregnancies', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='Glucose', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='BloodPressure', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='SkinThickness', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='Insulin', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='BMI', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='DiabetesPedigreeFunction', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "feature_columns = []\n",
    "for key in train_x.keys():\n",
    "    feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.3 Instantiate an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpi137vm9t\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpi137vm9t', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f572ed01b38>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.LinearClassifier(feature_columns=feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.4 Train, evaluate and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpi137vm9t/model.ckpt.\n",
      "INFO:tensorflow:loss = 69.31472, step = 1\n",
      "INFO:tensorflow:global_step/sec: 500.772\n",
      "INFO:tensorflow:loss = 49.663376, step = 101 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 765.293\n",
      "INFO:tensorflow:loss = 46.778423, step = 201 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 729.327\n",
      "INFO:tensorflow:loss = 44.855316, step = 301 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.145\n",
      "INFO:tensorflow:loss = 44.8329, step = 401 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.033\n",
      "INFO:tensorflow:loss = 48.07172, step = 501 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.238\n",
      "INFO:tensorflow:loss = 44.432693, step = 601 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.167\n",
      "INFO:tensorflow:loss = 43.436172, step = 701 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.353\n",
      "INFO:tensorflow:loss = 54.44357, step = 801 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.345\n",
      "INFO:tensorflow:loss = 54.23515, step = 901 (0.153 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpi137vm9t/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 45.84385.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-31-22:45:23\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpi137vm9t/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-31-22:45:23\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.7708333, accuracy_baseline = 0.6510416, auc = 0.8720597, auc_precision_recall = 0.7587766, average_loss = 0.4344716, global_step = 1000, label/mean = 0.34895834, loss = 41.709274, prediction/mean = 0.34622833\n",
      "\n",
      "Test set accuracy: 0.771\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpi137vm9t/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "Prediction is \"0\" (68.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (90.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (84.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (87.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (88.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (55.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (65.6%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (78.4%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (65.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (73.4%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (69.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (81.5%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (70.0%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (78.6%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (97.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (53.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (82.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (86.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (67.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (96.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (74.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (64.9%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (82.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (81.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (93.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (94.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (96.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (67.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (84.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (80.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (75.1%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (74.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (76.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (64.0%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (83.6%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (96.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (93.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (93.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (86.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (58.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (64.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (93.8%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (75.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (89.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (73.6%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (59.8%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (86.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (84.9%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (84.8%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (88.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (76.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (67.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (55.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (90.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (66.7%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (86.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (53.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (50.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (92.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (72.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (69.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (63.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (84.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (55.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (62.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (65.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (73.5%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (53.0%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (80.6%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (74.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (57.3%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (91.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (71.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (77.4%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (90.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (80.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (87.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (86.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (82.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (67.5%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (52.5%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (78.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (77.1%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (88.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (66.4%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (90.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (76.4%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (92.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (89.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (96.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (77.7%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (50.6%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (92.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (78.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (89.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (76.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (74.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (92.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (85.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (84.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (77.4%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (89.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (51.5%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (87.3%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (80.0%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (98.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (62.8%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (65.4%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (68.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (90.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (97.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (98.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (92.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (51.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (96.1%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (89.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (55.6%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (61.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (76.7%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (91.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (64.9%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (94.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (56.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (87.3%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (61.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (58.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (74.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (96.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (79.8%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (81.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (83.1%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (70.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (92.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (86.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (88.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (95.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (79.7%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (88.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (58.8%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (71.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (94.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (64.7%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (90.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (70.4%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (97.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (82.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (83.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (84.8%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (88.8%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (95.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (90.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (72.3%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (71.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (90.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (67.8%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (78.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (95.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (50.0%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (86.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (68.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (87.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (74.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (85.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (60.1%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (85.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (77.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (57.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (87.9%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (96.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (59.8%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (90.8%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (94.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (73.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (67.1%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (88.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (83.5%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (77.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (84.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (90.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (90.6%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (96.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (95.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (84.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (94.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (89.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (55.7%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (87.5%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (80.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (91.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (95.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (88.0%), expected \"1\"\n"
     ]
    }
   ],
   "source": [
    "classifier.train(input_fn=lambda:input_fn_train(train_x, train_y, 100), steps=1000)\n",
    "eval_result = classifier.evaluate(input_fn=lambda:input_fn_evaluate(test_x, test_y, 100))\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n",
    "predictions = classifier.predict(input_fn=lambda:input_fn_predict(test_x, 100))\n",
    "\n",
    "template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "for pred_dict, expec in zip(predictions, test_y):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "    print(template.format(class_id, 100 * probability, expec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Analyze with Neural Network\n",
    "\n",
    "TensorFlow is especially suitable for building neural networks. Let's have a look of how to build a [Deep Neural Network](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.0 What Is Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since TensorFlow is especially useful for building neural network model, in this section I will introduce some basic knowledge about what a neural network is and providez a small example.\n",
    "\n",
    "Neural Network has the advantage of fitting a non-linear model without manual adjustment. When the data distribution gets too complex for people to figure out a suitable distribution model intuitively, neural network becomes one of the top solutions here.\n",
    "\n",
    "Specifically, instead of building a set of linear relations from the inputs to the outputs, neural network takes in several hidden layers in the middle that apply extra linear and non-linear mappings, thus using a network of small neurons to form the whole mathemitical model. The following picture show a dense neural network where dense means edges exists among any pair of nodes in the adjecent layers, i.e. the network is fully connected.\n",
    "\n",
    "![title](images/NeuralNetwork.jpg)\n",
    "\n",
    "Credit: https://www.tutorialspoint.com/artificial_intelligence/artificial_intelligence_neural_networks.htm\n",
    "\n",
    "For more information about neural network a possible reference could be [Google's machine learning crash course](https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/video-lecture)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.1 Create input function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I will just reuse the input functions from the previous section for convenience. This is also to show you how convenient and decouple it is when building machine learning models with TensorFlow. Datasets processing can be totally seperated from models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.2 Define the feature columns\n",
    "\n",
    "This part is still the same as in the previous logistic regression section. So I will still just reuse the feature columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.3 Instantiate an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpcu_4mw1z\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpcu_4mw1z', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f575ec24c88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns, hidden_units=[12, 12, 8, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.4 Train, evaluate and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpcu_4mw1z/model.ckpt.\n",
      "INFO:tensorflow:loss = 80.99995, step = 1\n",
      "INFO:tensorflow:global_step/sec: 462.591\n",
      "INFO:tensorflow:loss = 44.04418, step = 101 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.544\n",
      "INFO:tensorflow:loss = 42.05944, step = 201 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.995\n",
      "INFO:tensorflow:loss = 41.93837, step = 301 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.128\n",
      "INFO:tensorflow:loss = 34.489605, step = 401 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.688\n",
      "INFO:tensorflow:loss = 28.193619, step = 501 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.816\n",
      "INFO:tensorflow:loss = 29.680841, step = 601 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 624.309\n",
      "INFO:tensorflow:loss = 33.56078, step = 701 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.294\n",
      "INFO:tensorflow:loss = 29.994516, step = 801 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.734\n",
      "INFO:tensorflow:loss = 41.473328, step = 901 (0.218 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpcu_4mw1z/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 24.34102.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-31-22:45:28\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpcu_4mw1z/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-31-22:45:28\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.8229167, accuracy_baseline = 0.6510416, auc = 0.8727761, auc_precision_recall = 0.7204302, average_loss = 0.46212518, global_step = 1000, label/mean = 0.34895834, loss = 44.364017, prediction/mean = 0.33871615\n",
      "\n",
      "Test set accuracy: 0.823\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpcu_4mw1z/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "\n",
      "Prediction is \"1\" (52.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (81.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (96.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (78.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (97.5%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (95.9%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (88.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (76.4%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (94.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (83.7%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (71.6%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (90.1%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (97.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (71.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (97.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (61.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (82.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (91.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (74.3%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (84.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (97.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (98.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (62.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (96.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (91.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (84.0%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (91.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (98.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (72.5%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (93.1%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (52.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (98.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (59.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (87.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (92.9%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (75.3%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (82.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (87.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (97.7%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (100.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (78.6%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (92.4%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (99.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (93.6%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (94.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (93.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (86.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (85.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (87.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (87.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (86.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (87.4%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (93.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (67.7%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (99.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (74.1%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (95.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (88.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (94.0%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (85.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (98.0%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (93.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (76.9%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (99.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (93.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (85.9%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (99.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (97.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (98.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (88.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (73.4%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (74.8%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (82.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (73.7%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (99.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (70.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (74.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (90.7%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (97.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (95.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (93.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (96.4%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (62.5%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (99.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (93.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (79.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (97.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (92.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (96.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (89.8%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (97.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (87.6%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (98.1%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (84.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (99.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (76.4%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (66.9%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (72.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (96.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (84.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (86.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (85.1%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (67.3%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (90.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (99.8%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (98.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (81.1%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (99.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (73.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (86.7%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (86.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (73.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (85.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (96.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (94.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (88.5%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (72.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (95.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (96.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (94.3%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (97.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (92.1%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (91.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (87.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (99.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (58.7%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (99.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (79.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (90.1%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (91.9%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (84.9%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (99.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (78.1%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (78.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (60.9%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (99.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (96.8%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (98.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (82.3%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (95.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (97.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (85.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (68.9%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (91.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (97.7%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (69.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (90.1%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (99.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (89.6%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (85.2%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (99.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (93.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (66.4%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (94.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (93.9%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (94.2%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (80.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (98.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (98.6%), expected \"1\"\n",
      "\n",
      "Prediction is \"0\" (99.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.9%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (99.0%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (98.6%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (96.5%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (83.5%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (91.4%), expected \"1\"\n",
      "\n",
      "Prediction is \"1\" (99.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (75.4%), expected \"0\"\n",
      "\n",
      "Prediction is \"0\" (98.8%), expected \"0\"\n",
      "\n",
      "Prediction is \"1\" (98.8%), expected \"1\"\n"
     ]
    }
   ],
   "source": [
    "classifier.train(input_fn=lambda:input_fn_train(train_x, train_y, 100), steps=1000)\n",
    "eval_result = classifier.evaluate(input_fn=lambda:input_fn_evaluate(test_x, test_y, 100))\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n",
    "predictions = classifier.predict(input_fn=lambda:input_fn_predict(test_x, 100))\n",
    "\n",
    "template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
    "for pred_dict, expec in zip(predictions, test_y):\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "    print(template.format(class_id, 100 * probability, expec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, we can easily find that neural network is not a good solution for such a simple problem. Actually this diabetes problem is very much like to breast cancer classification problem shown in calss, which is a calssic problem suitable for solving with linear classification. Thus in this section, let's try to solve it in another way with a linear classification model - Logistic Regression. The detailed realization will be using an existing Estimator - tf.estimator.LinearClassifier (https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
